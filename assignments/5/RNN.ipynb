{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - RNN\n",
    "## Task: 4\n",
    "Author: Soham Vaishnav\n",
    "Roll No.: 2022112002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "import os\n",
    "import sys \n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "AssignDIR = os.path.dirname(os.path.dirname(os.path.abspath('RNN.ipynb')))\n",
    "CurrDIR = os.path.dirname(os.path.abspath('RNN.ipynb'))\n",
    "UserDIR = os.path.dirname(AssignDIR)\n",
    "\n",
    "sys.path.append(UserDIR)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import librosa\n",
    "\n",
    "RawDataDIR = os.path.join(UserDIR, \"./data/external/\")\n",
    "PreProcessDIR = os.path.join(UserDIR, \"./data/interim/5/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading/Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(data_length, max_seq_length=16):\n",
    "    data= []\n",
    "    seq_lengths = []\n",
    "    np.random.seed(0)\n",
    "    for i in range(data_length):\n",
    "        seq_length = np.random.choice(list(range(1, max_seq_length + 1)))\n",
    "        seq_lengths.append(seq_length)\n",
    "        seq = np.random.choice([0, 1], size=(seq_length, 1)).tolist()\n",
    "        if (len(seq) < max_seq_length):\n",
    "            for i in range(max_seq_length - len(seq)):\n",
    "                seq.append([0])\n",
    "        data.append([seq, np.sum(seq)])\n",
    "    return data, seq_lengths\n",
    "\n",
    "data_seq, seq_lengths = getData(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1], [1], [0], [1], [1], [1], [1], [1], [1], [1], [0], [0], [1], [0], [0], [0]], 10]\n",
      "[[[0], [0], [0], [0], [1], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0]], 2]\n",
      "[[[0], [0], [1], [1], [1], [1], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0]], 5]\n",
      "[[[1], [0], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], 3]\n",
      "[[[1], [0], [0], [1], [0], [1], [1], [1], [1], [1], [0], [1], [0], [1], [1], [1]], 11]\n",
      "[[[0], [1], [0], [0], [1], [1], [0], [1], [0], [1], [0], [0], [0], [0], [0], [1]], 6]\n",
      "[[[0], [0], [0], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], 2]\n",
      "[[[0], [0], [1], [0], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0]], 7]\n",
      "[[[1], [1], [0], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], 3]\n",
      "[[[1], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]], 2]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(data_seq[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_seq[:int(len(data_seq)*0.8)]\n",
    "train_seq_lengths = seq_lengths[:int(len(data_seq)*0.8)]\n",
    "val_data = data_seq[int(len(data_seq)*0.8):int(len(data_seq)*0.9)]\n",
    "val_seq_lengths = seq_lengths[int(len(data_seq)*0.8):int(len(data_seq)*0.9)]\n",
    "test_data = data_seq[int(len(data_seq)*0.9):]\n",
    "test_seq_lengths = seq_lengths[int(len(data_seq)*0.9):]\n",
    "\n",
    "class BitsData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0], dtype=torch.float32), torch.tensor(self.data[idx][1], dtype=torch.float32)\n",
    "    \n",
    "train_loader = DataLoader(BitsData(train_data), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(BitsData(val_data), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(BitsData(test_data), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 0.001,\n",
    "    'epochs': 10,\n",
    "    'hidden_size': 64,\n",
    "    'n_layers': 2,\n",
    "    'dropout': 0.2,\n",
    "    'batch_norm': False,\n",
    "    'input_size': 1,\n",
    "    'nonlinearity': 'tanh'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, MAE Train Loss: 2.1718273162841797, Val Loss: 2.264871597290039\n",
      "Epoch 2/10, MAE Train Loss: 0.10454991459846497, Val Loss: 0.1064460277557373\n",
      "Epoch 3/10, MAE Train Loss: 0.20521315932273865, Val Loss: 0.16167736053466797\n",
      "Epoch 4/10, MAE Train Loss: 0.10896608233451843, Val Loss: 0.08722268044948578\n",
      "Epoch 5/10, MAE Train Loss: 0.07096417248249054, Val Loss: 0.08848828822374344\n",
      "Epoch 6/10, MAE Train Loss: 0.07445666939020157, Val Loss: 0.09601453691720963\n",
      "Epoch 7/10, MAE Train Loss: 0.05365116521716118, Val Loss: 0.052614133805036545\n",
      "Epoch 8/10, MAE Train Loss: 0.03241845965385437, Val Loss: 0.035465121269226074\n",
      "Epoch 9/10, MAE Train Loss: 0.024574534967541695, Val Loss: 0.03446609154343605\n",
      "Epoch 10/10, MAE Train Loss: 0.05387723073363304, Val Loss: 0.08943294733762741\n",
      "Model trained successfully\n"
     ]
    }
   ],
   "source": [
    "from models.rnn.rnn import BitCounterRNN\n",
    "\n",
    "model = BitCounterRNN(config)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "model.fit(train_loader=train_loader, val_loader=val_loader, \n",
    "          criterion=criterion, optimizer=optimizer, lr=config['lr'], n_epochs=config['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at  c:\\Users\\Admin\\smai-m24-assignments-SohamVaishnav\\assignments\\5\\RNN_best_model_1.pth\n"
     ]
    }
   ],
   "source": [
    "model.save_model(os.path.join(CurrDIR, 'RNN_best_model_1.pth')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing against random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5896"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def random_baseline(seq_length):\n",
    "    np.random.seed(0)\n",
    "    return [np.random.randint(0, length) for length in seq_length]\n",
    "\n",
    "def compare_baseline(test_loader, baseline, seq_lengths):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for x, y in test_loader:\n",
    "        y_true.extend(y.numpy())\n",
    "    y_pred = baseline(seq_lengths)\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "compare_baseline(test_loader, random_baseline, test_seq_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, MAE for random baseline is much worse than the MAE of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalisation_data_17, seq_lengths_17 = getData(1000, 17)\n",
    "generalisation_data_18, seq_lengths_18 = getData(1000, 18)\n",
    "\n",
    "generalisation_loader_17 = DataLoader(BitsData(generalisation_data_17), batch_size=64, shuffle=True)\n",
    "generalisation_loader_18 = DataLoader(BitsData(generalisation_data_18), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on 17-length sequences: 0.630487859249115\n",
      "Loss on 18-length sequences: 1.2029125690460205\n"
     ]
    }
   ],
   "source": [
    "loss_17 = model.evaluate(generalisation_loader_17, criterion)\n",
    "loss_18 = model.evaluate(generalisation_loader_18, criterion)\n",
    "\n",
    "print(f\"Loss on 17-length sequences: {loss_17}\")\n",
    "print(f\"Loss on 18-length sequences: {loss_18}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss vs Length of Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_seq = []\n",
    "for i in range(1, 33):\n",
    "    generalisation_data = getData(1000, i)\n",
    "    generalisation_loader = DataLoader(BitsData(generalisation_data), batch_size=64, shuffle=True)\n",
    "    loss = model.evaluate(generalisation_loader, criterion)\n",
    "    losses_seq.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32
         ],
         "y": [
          5.606153964996338,
          7.29695987701416,
          7.396368980407715,
          7.451293468475342,
          6.92003870010376,
          6.293318748474121,
          5.938035011291504,
          5.041207313537598,
          4.493251800537109,
          3.98966383934021,
          3.055727005004883,
          2.599419116973877,
          1.9984782934188843,
          1.100358009338379,
          0.737708330154419,
          0.017623594030737877,
          0.7943439483642578,
          1.077358365058899,
          1.7652283906936646,
          2.3303050994873047,
          2.6199100017547607,
          3.3249645233154297,
          3.7646005153656006,
          4.090813159942627,
          4.523482799530029,
          4.886305809020996,
          5.13023042678833,
          5.676609039306641,
          6.072259902954102,
          6.888341426849365,
          7.372453689575195,
          7.678371429443359
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Loss on sequences of different lengths"
        },
        "xaxis": {
         "title": {
          "text": "Sequence length"
         }
        },
        "yaxis": {
         "title": {
          "text": "L1 loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(range(1, 33)), y=losses_seq, mode='lines+markers'))\n",
    "fig.update_layout(title='Loss on sequences of different lengths',\n",
    "                   xaxis_title='Sequence length',\n",
    "                   yaxis_title='L1 loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason:\\\n",
    "The reason for the above trend is that since the model is trained for 16-bit data, it is not able to generalise to either of the extremes. This can also be traced down to the fact that the model has only 2 layers which implies that it focusses on only the last two input streams - shows why the MAE for 14, 15, 17 and 18 bit lengths is closer to that of 16. Beyond 18, the model has no memory and has't been trained for so it performs quite poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2 - Optical Character Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section has been done after referring to several resources including LLM services. However, I have tried to code it in my way after taking cues from the resources. Therefore, there would be some amount of overlap in the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images created...\n",
      "1000 images created...\n",
      "2000 images created...\n",
      "3000 images created...\n",
      "4000 images created...\n",
      "5000 images created...\n",
      "6000 images created...\n",
      "7000 images created...\n",
      "8000 images created...\n",
      "9000 images created...\n",
      "Dataset creation completed.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "output_dir = \"word_image_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "word_list = words.words()\n",
    "unique_words = list(set(word_list))[:10000]\n",
    "\n",
    "font_path = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
    "font_size = 200\n",
    "\n",
    "for i, word in enumerate(unique_words):\n",
    "    img = Image.new(\"RGB\", (256, 64), \"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    text_bbox = draw.textbbox((0, 0), word, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "    text_x = (256 - text_width) // 2\n",
    "    text_y = (64 - text_height) // 2\n",
    "    draw.text((text_x, text_y), word, fill=\"black\", font=font)\n",
    "\n",
    "    img.save(os.path.join(output_dir, f\"{word}.png\"))\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i} images created...\")\n",
    "\n",
    "print(\"Dataset creation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has been clipped to 10000 samples due to compute issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN+RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, image_files, gt_labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.gt_labels = gt_labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      img_path = self.image_files[idx]\n",
    "      image = Image.open(img_path).convert(\"L\")\n",
    "      if self.transform:\n",
    "        image = self.transform(image)\n",
    "      gt_label = self.gt_labels[idx]\n",
    "      return image, torch.tensor(gt_label, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images, dim=0)\n",
    "\n",
    "    labels = [torch.tensor(label) for label in labels]\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "\n",
    "    return images, labels_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataloader(image_dir, batch_size, transorm=None, collate_fn=None):\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    image_paths = [os.path.join(image_dir, file) for file in image_files]\n",
    "    gt_labels = [os.path.splitext(file)[0] for file in image_files]\n",
    "    gt_labels_concat = [char for word in gt_labels for char in word]\n",
    "    gt_label_encoded = preprocessing.LabelEncoder().fit(gt_labels_concat)\n",
    "    gt_labels_new = [gt_label_encoded.transform(list(word))+1 for word in gt_labels]\n",
    "\n",
    "    train_imgs, test_imgs, train_labels, test_labels, train_raw_labels, test_raw_labels = train_test_split(image_paths, gt_labels_new, gt_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = CreateDataset(image_files=train_imgs, gt_labels=train_labels, transform=transorm)\n",
    "    test_dataset = CreateDataset(image_files=test_imgs, gt_labels=test_labels, transform=transorm)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, test_loader, gt_label_encoded, test_labels\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "train_loader, test_loader, encoder, test_gt = CreateDataloader(\"word_image_dataset\", 32, transform, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 256])\n",
      "torch.Size([32, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6736\\867717337.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(label) for label in labels]\n"
     ]
    }
   ],
   "source": [
    "for img, label in train_loader:\n",
    "    print(img.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6736\\867717337.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(label) for label in labels]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47, 40, 44, 27, 39, 39, 31, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    plt.imshow(images[1].squeeze(), cmap='gray')\n",
    "    plt.show()\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer and Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(dataloader, total=len(dataloader))\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, loss = model(images, labels)\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    return total_loss/len(dataloader)\n",
    "\n",
    "def eval_loop(model, optimiser, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds = []\n",
    "    loop = tqdm(dataloader, total=len(dataloader))\n",
    "    with torch.no_grad():\n",
    "      for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs, loss = model(images, labels)\n",
    "        total_loss += loss\n",
    "        preds.append(outputs)\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    return preds, total_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(preds, label_encoder):\n",
    "    preds = preds.permute(1, 0, 2)\n",
    "    preds = torch.softmax(preds, dim=2)\n",
    "    preds = torch.argmax(preds, dim=2)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "    pred_words = []\n",
    "    for pred in preds:\n",
    "        if (pred == 0).any():\n",
    "            pred = pred[:np.argmax(pred == 0)]\n",
    "        pred_str = label_encoder.inverse_transform(pred-1)\n",
    "        pred_words.append(pred_str)\n",
    "    return pred_words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNRNNModel(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels, dropout):\n",
    "        super(CNNRNNModel, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.rnn = nn.LSTM(64, 32, 2, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.output = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.fc = nn.Linear(1024, 64)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        features = self.cnn(x)\n",
    "        b, c, h, w = features.size()\n",
    "        features = features.permute(0, 3, 1, 2).view(b, w, -1)\n",
    "\n",
    "        fcn_out = self.fc(features)\n",
    "        fcn_out = self.do(fcn_out)\n",
    "\n",
    "        rnn_out, _ = self.rnn(fcn_out)\n",
    "\n",
    "        output = self.output(rnn_out).permute(1, 0, 2)\n",
    "\n",
    "        if (labels is not None):\n",
    "          out_log = F.log_softmax(output, dim=2)\n",
    "          input_lengths = torch.full(size=(b,), fill_value=output.size(0), dtype=torch.long)\n",
    "          target_lengths = torch.full(size=(b,), fill_value=labels.size(1), dtype=torch.long)\n",
    "          loss = nn.CTCLoss(blank=0)(out_log, labels, input_lengths, target_lengths)\n",
    "          # print(type(output))\n",
    "          return output, loss\n",
    "        else:\n",
    "          return output, None\n",
    "\n",
    "model = CNNRNNModel(52, in_channels=1, dropout=0.2)\n",
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "def evaluate_metric(preds, targets, encoder):\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "\n",
    "    preds_decoded = torch.argmax(preds, dim=2) \n",
    "\n",
    "    for pred, target in zip(preds_decoded, targets):\n",
    "        pred_str = encoder.inverse_transform(pred)\n",
    "        target_str = encoder.inverse_transform(target)\n",
    "\n",
    "        for p, t in zip(pred_str, target_str):\n",
    "            if p == t:\n",
    "                correct_chars += 1\n",
    "            total_chars += 1\n",
    "\n",
    "    return correct_chars / total_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6736\\867717337.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(label) for label in labels]\n",
      "100%|| 250/250 [01:59<00:00,  2.09it/s, loss=2.9] \n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s, loss=3.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Train loss: 4.804193627357483, Val_loss: 3.027109146118164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:59<00:00,  2.09it/s, loss=1.88] \n",
      "100%|| 63/63 [00:12<00:00,  4.90it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Train loss: 1.746430400133133, Val_loss: 1.5545705556869507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:40<00:00,  2.49it/s, loss=1.64] \n",
      "100%|| 63/63 [00:11<00:00,  5.50it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 - Train loss: 1.6121973214149474, Val_loss: 1.5547677278518677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:33<00:00,  2.67it/s, loss=1.88] \n",
      "100%|| 63/63 [00:10<00:00,  5.89it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 - Train loss: 1.6051521275043488, Val_loss: 1.5547298192977905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:28<00:00,  2.82it/s, loss=1.4] \n",
      "100%|| 63/63 [00:10<00:00,  5.84it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 - Train loss: 1.5917370755672455, Val_loss: 1.55474853515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:28<00:00,  2.82it/s, loss=2.07] \n",
      "100%|| 63/63 [00:10<00:00,  5.84it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 - Train loss: 1.5932969262599945, Val_loss: 1.5548661947250366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:26<00:00,  2.90it/s, loss=1.89]\n",
      "100%|| 63/63 [00:10<00:00,  6.26it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 - Train loss: 1.6139304370880128, Val_loss: 1.5548958778381348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:25<00:00,  2.94it/s, loss=2.24] \n",
      "100%|| 63/63 [00:10<00:00,  6.25it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 - Train loss: 1.5970918126106262, Val_loss: 1.5546289682388306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:48<00:00,  2.30it/s, loss=1.53] \n",
      "100%|| 63/63 [00:20<00:00,  3.10it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 - Train loss: 1.609384905576706, Val_loss: 1.554884672164917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:52<00:00,  1.45it/s, loss=1.74] \n",
      "100%|| 63/63 [00:20<00:00,  3.11it/s, loss=1.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 - Train loss: 1.6198647019863128, Val_loss: 1.5549041032791138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=5, verbose=True)\n",
    "\n",
    "for epochs in range(10):\n",
    "    train_loss = train_loop(model, optimizer, train_loader, 'cpu')\n",
    "    preds, test_loss = eval_loop(model, optimizer, test_loader, 'cpu')\n",
    "    print(f\"Epoch: {epochs} - Train loss: {train_loss}, Val_loss: {test_loss}\")\n",
    "    # for i in range(5):\n",
    "    #     print(evaluate_metric(preds[i], test_gt[i], encoder))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
